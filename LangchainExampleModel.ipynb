{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1q0CCQKhcFX"
      },
      "outputs": [],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "pSW8g32Fnx7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f099a11"
      },
      "source": [
        "!pip install langchain-community"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "llm = ChatOpenAI(\n",
        "    openai_api_base = \"https://openrouter.ai/api/v1\",\n",
        "    openai_api_key = \"<OPEN_ROUTER_API_KEY>\",\n",
        "    model = \"MODEL_NAME\",\n",
        "    temperature=0.9) #max_tokens=100openrouter - only for colab user"
      ],
      "metadata": {
        "id": "_b13pUNqk_e2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing Think area"
      ],
      "metadata": {
        "id": "CmGSl-32iIAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def remove_think_sections(text):\n",
        "    return re.sub(r\"<think>.*?</think>\", \"\", text)"
      ],
      "metadata": {
        "id": "T64HP5IkiHGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic Run"
      ],
      "metadata": {
        "id": "1KIEESebiMf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"what are the 5 industries in thanjavur?\""
      ],
      "metadata": {
        "id": "qmTpF5Z-iQet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = llm.predict(text)\n",
        "output = remove_think_sections(output)\n",
        "print(output)"
      ],
      "metadata": {
        "id": "a6087EG_iaVS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt Template"
      ],
      "metadata": {
        "id": "0F1lobKTi2eI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=['cuisine'],\n",
        "    template=template\n",
        ")\n",
        "\n",
        "formatted_prompt = prompt.format(cuisine=\"Chinese-sichuang-Tang\")\n",
        "print(formatted_prompt)"
      ],
      "metadata": {
        "id": "tn5TnbqKiyHB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Few Shot Prompt"
      ],
      "metadata": {
        "id": "1D4QDkphjNCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import FewShotPromptTemplate\n",
        "\n",
        "\n",
        "examples = [\n",
        "    {\"word\": \"cat\", \"definition\": \"A small domesticated carnivorous mammal.\"},\n",
        "    {\"word\": \"dog\", \"definition\": \"A domesticated carnivorous mammal that typically has a long snout.\"},\n",
        "]\n",
        "\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"word\", \"definition\"],\n",
        "    template=\"Word: {word}\\nDefinition: {definition}\\n\"\n",
        ")\n",
        "\n",
        "few_shot_prompt = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=\"Keep the answer very short and consise and Define the following words:\",\n",
        "    suffix=\"Word: {input}\\nDefinition:\",\n",
        "    input_variables=[\"input\"],\n",
        ")\n",
        "\n",
        "output = (few_shot_prompt.format(input=\"Lion\"))\n",
        "print (output)"
      ],
      "metadata": {
        "id": "nPkZ_3mni_Is"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = llm.predict(output)\n",
        "output = remove_think_sections(output)\n",
        "print(output)"
      ],
      "metadata": {
        "id": "tRgn60Y1jTIN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple Chain"
      ],
      "metadata": {
        "id": "kMszlOaOjYaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"topic\"],\n",
        "    template=\"Give me a tweet idea about {topic}\"\n",
        ")\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "response = chain.run(\"AI in education\")\n",
        "response = remove_think_sections(response)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "d1HCW3iijcbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sequential Chain"
      ],
      "metadata": {
        "id": "ty_-ca6djmU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SequentialChain\n",
        "\n",
        "# Prompt 1: Generate title\n",
        "title_prompt = PromptTemplate(\n",
        "    input_variables=[\"topic\"],\n",
        "    template=\"Write a compelling blog post title about {topic}. only give one one title as the output nothing more than that\"\n",
        ")\n",
        "title_chain = LLMChain(llm=llm, prompt=title_prompt, output_key=\"title\")\n",
        "\n",
        "# Prompt 2: Use title to generate intro\n",
        "intro_prompt = PromptTemplate(\n",
        "    input_variables=[\"title\"],\n",
        "    template=\"Write a short blog introduction for the post titled: {title}. only give the introduction as the output nothing more than that. have bullet points and emojis in the intro\"\n",
        ")\n",
        "intro_chain = LLMChain(llm=llm, prompt=intro_prompt, output_key=\"intro\")\n",
        "\n",
        "# Chain them together\n",
        "overall_chain = SequentialChain(\n",
        "    chains=[title_chain, intro_chain],\n",
        "    input_variables=[\"topic\"],\n",
        "    output_variables=[\"title\", \"intro\"]\n",
        ")\n",
        "\n",
        "result = overall_chain.invoke(\"LangChain for AI-powered apps\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "FVvjshnLjqmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result[\"intro\"])"
      ],
      "metadata": {
        "id": "uQ4BSaLdj1Bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom Template"
      ],
      "metadata": {
        "id": "Oon71ZHdj1vd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.schema import BaseOutputParser\n",
        "\n",
        "\n",
        "memory = ConversationBufferMemory()\n",
        "\n",
        "class RemoveThinkParser(BaseOutputParser):\n",
        "    def parse(self, text: str) -> str:\n",
        "        # remove <think>...</think> blocks\n",
        "        return re.sub(r\"<think>.*?</think>\", \"\", text, flags=re.DOTALL).strip()\n",
        "\n",
        "custom_prompt = PromptTemplate(\n",
        "    input_variables=[\"history\", \"input\"],\n",
        "    template=\"\"\"\n",
        "You are a helpful and concise assistant.\n",
        "\n",
        "{history}\n",
        "Human: {input}\n",
        "AI:\"\"\"\n",
        ")\n",
        "\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=memory,\n",
        "    verbose=True,\n",
        "    prompt=custom_prompt,\n",
        "    output_parser=RemoveThinkParser()\n",
        ")\n",
        "\n",
        "\n",
        "print (conversation.predict(input=\"Hi, my name is Deepan.\"))\n",
        "\n",
        "\n",
        "print (conversation.predict(input=\"Whatâ€™s my name?\"))\n",
        "\n"
      ],
      "metadata": {
        "id": "vE2Z5T2-j4Rv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}